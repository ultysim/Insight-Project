{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(6000*2, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, d_obs, deterministic=False):\n",
    "        logits = self.layers(d_obs)\n",
    "        if deterministic:\n",
    "            action = torch.argmax(logits[0])\n",
    "            action_prob = 1.0\n",
    "        else:\n",
    "            c = torch.distributions.Categorical(logits=logits)\n",
    "            action = c.sample()\n",
    "            action_prob = c.probs[0, action]\n",
    "        return action, action_prob, logits\n",
    "\n",
    "    def state_to_tensor(self, I, opponent=False):\n",
    "        \"\"\" prepro 210x160x3 uint8 frame into 6000 (75x80) 1D float vector \"\"\"\n",
    "        if I is None:\n",
    "            return torch.zeros(1, 6000)\n",
    "        if opponent:\n",
    "            I = np.fliplr(I)\n",
    "        I = I[35:185] # crop - remove 35px from start & 25px from end of image in x, to reduce redundant parts of image (i.e. after ball passes paddle)\n",
    "        I = I[::2,::2,0] # downsample by factor of 2.\n",
    "        I[I == 144] = 0 # erase background (background type 1)\n",
    "        I[I == 109] = 0 # erase background (background type 2)\n",
    "        I[I != 0] = 1 # everything else (paddles, ball) just set to 1. this makes the image grayscale effectively\n",
    "        return torch.from_numpy(I.astype(np.float32).ravel()).unsqueeze(0)\n",
    "\n",
    "    def pre_process(self, x, prev_x, opponent=False):\n",
    "        #return self.state_to_tensor(x) - self.state_to_tensor(prev_x)\n",
    "        return torch.cat([self.state_to_tensor(x, opponent), self.state_to_tensor(prev_x, opponent)], dim=1)\n",
    "\n",
    "    def convert_action(self, action):\n",
    "        return action + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opponent_col(obs):\n",
    "    return obs.cpu().numpy().reshape(75, 80)[:, 8:10]\n",
    "\n",
    "def get_player_col(obs):\n",
    "    return obs.cpu().numpy().reshape(75, 80)[:, 70:72]\n",
    "\n",
    "def get_opponent_screen(obs):\n",
    "    numpy_obs = np.fliplr(obs.cpu().numpy().reshape(75, 80))\n",
    "    return torch.from_numpy(numpy_obs.astype(np.float32).ravel()).unsqueeze(0)\n",
    "\n",
    "\n",
    "def get_opponent_action(x, prev_x):\n",
    "    \"\"\"Input: x, current screen; prev_x: previous screen\n",
    "    Output: Returns opponent action. -1 for no action, 0 for up, 1 for down\"\"\"\n",
    "    if prev_x is None:\n",
    "        prev_x = x\n",
    "    movement = x - prev_x\n",
    "    op_window = movement[35:194, 16:20]\n",
    "    #Remove 0s and see the action\n",
    "    op_window = op_window[op_window != 0]\n",
    "    if len(op_window) == 0:\n",
    "        return -1\n",
    "    if op_window[0] < 100:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_opponent_action_2(obs):\n",
    "    \"\"\"Input: x, current screen; prev_x: previous screen\n",
    "    Output: Returns opponent action. -1 for no action, 0 for up, 1 for down\"\"\"\n",
    "    unstack = obs.view(2, 75, 80)\n",
    "    obs = unstack[0] - unstack[1]\n",
    "    opponent = get_opponent_col(obs)\n",
    "    #Remove 0s and see the action\n",
    "    opponent = opponent[opponent != 0]\n",
    "    if len(opponent) == 0:\n",
    "        return -1\n",
    "    if opponent[0] > 0:\n",
    "        return 0\n",
    "    elif opponent[0] < 0:\n",
    "        return 1\n",
    "    return -2\n",
    "\n",
    "def is_overlap(I):\n",
    "    player = get_player_col(I)\n",
    "    opponent = get_opponent_col(I)\n",
    "    return np.sum(opponent[player == 1.]) >= 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('PongNoFrameskip-v4')\n",
    "_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()\n",
    "policy.load_state_dict(torch.load(\"params.ckpt\"))\n",
    "\n",
    "policy.train()\n",
    "\n",
    "#Define loss criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#Define the optimizer\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=0.001)#0.0001 stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2626 % overlap\n",
      "-3.0 score delta\n",
      "0.2927 % overlap\n",
      "1.0 score delta\n",
      "0.2882 % overlap\n",
      "-6.0 score delta\n",
      "0.3088 % overlap\n",
      "2.0 score delta\n",
      "0.2987 % overlap\n",
      "-1.0 score delta\n",
      "0.2895 % overlap\n",
      "2.0 score delta\n",
      "0.2826 % overlap\n",
      "1.0 score delta\n",
      "0.2796 % overlap\n",
      "1.0 score delta\n",
      "0.2997 % overlap\n",
      "-2.0 score delta\n",
      "0.2974 % overlap\n",
      "0.0 score delta\n",
      "0.2867 % overlap\n",
      "0.0 score delta\n",
      "0.3051 % overlap\n",
      "-5.0 score delta\n",
      "0.2902 % overlap\n",
      "-2.0 score delta\n",
      "0.252 % overlap\n",
      "-2.0 score delta\n",
      "0.298 % overlap\n",
      "-1.0 score delta\n",
      "0.2943 % overlap\n",
      "-3.0 score delta\n",
      "0.2925 % overlap\n",
      "6.0 score delta\n",
      "0.2977 % overlap\n",
      "-4.0 score delta\n",
      "0.3029 % overlap\n",
      "0.0 score delta\n",
      "0.2985 % overlap\n",
      "-1.0 score delta\n",
      "0.2806 % overlap\n",
      "2.0 score delta\n",
      "0.2882 % overlap\n",
      "-1.0 score delta\n",
      "0.2943 % overlap\n",
      "-1.0 score delta\n",
      "0.3024 % overlap\n",
      "4.0 score delta\n",
      "0.296 % overlap\n",
      "1.0 score delta\n",
      "0.2789 % overlap\n",
      "-4.0 score delta\n",
      "0.3064 % overlap\n",
      "4.0 score delta\n",
      "0.3214 % overlap\n",
      "0.0 score delta\n",
      "0.3206 % overlap\n",
      "6.0 score delta\n",
      "0.2835 % overlap\n",
      "-6.0 score delta\n"
     ]
    }
   ],
   "source": [
    "#GENERATE BASELINE:\n",
    "total_overlap = []\n",
    "total_score = []\n",
    "for episode in range(30):\n",
    "    prev_obs = None\n",
    "    obs = env.reset()\n",
    "    \n",
    "    overlap_hold = []\n",
    "    score = 0\n",
    "\n",
    "    for t in range(10000):\n",
    "        #Preprocess the images for more model and efficient state extraction:\n",
    "        a_obs = policy.pre_process(obs, prev_obs)\n",
    "        \n",
    "        #TODO: Fix this jank, but just for testing now:\n",
    "        filtered_obs = policy.state_to_tensor(obs)\n",
    "        overlap_hold.append(is_overlap(filtered_obs))\n",
    "\n",
    "        action, action_prob, _ = policy(a_obs)\n",
    "        op_action_pred, op_action_prob, op_action_logit = policy(op_obs)\n",
    "\n",
    "        prev_obs = obs\n",
    "        obs, reward, done, info = env.step(policy.convert_action(action))\n",
    "        score += reward\n",
    "        \n",
    "        if done:\n",
    "            print('Episode %d (%d timesteps) - Reward: %.2f' % (episode, t, reward))\n",
    "            break\n",
    "    \n",
    "    mean_overlap = np.mean(overlap_hold)\n",
    "    \n",
    "    print(\"{} % overlap\".format(mean_overlap))\n",
    "    print(\"{} score delta\".format(score))\n",
    "    env.close()\n",
    "    total_overlap.append(mean_overlap)\n",
    "    total_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overlap: 0.29300000000000004\n",
      "STD overlap: 0.014093331756543589\n",
      "Average score delta: -0.4\n",
      "STD score delta: 3.050682983639347\n"
     ]
    }
   ],
   "source": [
    "print(\"Average overlap:\", np.mean(total_overlap))\n",
    "print(\"STD overlap:\", np.std(total_overlap))\n",
    "print(\"Average score delta:\", np.mean(total_score))\n",
    "print(\"STD score delta:\", np.std(total_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(policy.parameters(), lr=0.001)#0.0001 stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4913277511961722% correct guesses\n",
      "0.8877450823783875 Cross Entropy Loss\n",
      "0.3047 % overlap\n"
     ]
    }
   ],
   "source": [
    "total_overlap = []\n",
    "for episode in range(1):\n",
    "    prev_obs = None\n",
    "    obs = env.reset()\n",
    "\n",
    "    op_obs = policy.pre_process(obs, prev_obs, opponent=True)\n",
    "\n",
    "    op_action_pred, op_action_prob, op_action_logit = policy(op_obs)\n",
    "\n",
    "    '''op_action_pred = -1\n",
    "    op_action_prob = 0\n",
    "    op_action_logit = 0'''\n",
    "\n",
    "    correct_hold = []\n",
    "    op_action_hold = []\n",
    "    op_action_prob_hold = []\n",
    "    op_action_logit_hold = torch.Tensor()\n",
    "    \n",
    "    overlap_hold = []\n",
    "\n",
    "\n",
    "\n",
    "    for t in range(10000):\n",
    "        #env.render()\n",
    "\n",
    "        #Preprocess the images for more model and efficient state extraction:\n",
    "        a_obs = policy.pre_process(obs, prev_obs)\n",
    "        op_obs = policy.pre_process(obs, prev_obs, opponent=True)\n",
    "        \n",
    "        ##############################################\n",
    "        ########## Checks for Overlap ################\n",
    "        \n",
    "        #TODO: Fix this jank, but just for testing now:\n",
    "        filtered_obs = policy.state_to_tensor(obs)\n",
    "        overlap_hold.append(is_overlap(filtered_obs))\n",
    "\n",
    "        op_action_real = get_opponent_action(obs, prev_obs)\n",
    "        #op_action_real = get_opponent_action_2(op_obs)\n",
    "\n",
    "        if op_action_real >= 0:\n",
    "            op_action_hold.append(torch.tensor(op_action_real))\n",
    "            op_action_prob_hold.append(op_action_prob)\n",
    "            op_action_logit_hold = torch.cat((op_action_logit_hold,op_action_logit))\n",
    "            correct_hold.append(op_action_real == op_action_pred)\n",
    "\n",
    "\n",
    "        action, action_prob, _ = policy(a_obs)\n",
    "        op_action_pred, op_action_prob, op_action_logit = policy(op_obs)\n",
    "\n",
    "        prev_obs = obs\n",
    "        obs, reward, done, info = env.step(policy.convert_action(action))\n",
    "\n",
    "        if done:\n",
    "            print('Episode %d (%d timesteps) - Reward: %.2f' % (episode, t, reward))\n",
    "            break\n",
    "    actions_stack = torch.stack(op_action_hold)\n",
    "    actions_stack = one_hot_embedding(actions_stack, 2)\n",
    "\n",
    "    op_action_logit_hold, actions_stack = op_action_logit_hold, actions_stack\n",
    "    # Clear the previous gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = criterion(op_action_logit_hold, actions_stack)\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    # Adjust weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    mean_overlap = np.mean(overlap_hold)\n",
    "    \n",
    "    \n",
    "    print(\"{}% correct guesses\".format(np.mean(correct_hold)))\n",
    "    print(\"{} Cross Entropy Loss\".format(loss.item()))\n",
    "    print(\"{} % overlap\".format(mean_overlap))\n",
    "    \n",
    "    total_overlap.append(mean_overlap)\n",
    "    \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(op_action_hold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_overlap = []\n",
    "for episode in range(10):\n",
    "    \n",
    "    correct_hold = []\n",
    "    op_action_hold = []\n",
    "    op_action_prob_hold = []\n",
    "    op_action_logit_hold = torch.Tensor()\n",
    "    \n",
    "    #Statistics to generate\n",
    "    trial_mean_overlap = []\n",
    "    trial_mean_std = []\n",
    "    trial_delta = []\n",
    "\n",
    "    for trial in range(30):\n",
    "        \n",
    "        prev_obs = None\n",
    "        obs = env.reset()\n",
    "\n",
    "        op_obs = policy.pre_process(obs, prev_obs, opponent=True)\n",
    "\n",
    "        op_action_pred, op_action_prob, op_action_logit = policy(op_obs)\n",
    "\n",
    "\n",
    "        overlap_hold = []\n",
    "        score = 0\n",
    "\n",
    "        for t in range(10000):\n",
    "            env.render()\n",
    "\n",
    "            #Preprocess the images for more model and efficient state extraction:\n",
    "            a_obs = policy.pre_process(obs, prev_obs)\n",
    "            op_obs = policy.pre_process(obs, prev_obs, opponent=True)\n",
    "\n",
    "            ##############################################\n",
    "            ########## Checks for Overlap ################\n",
    "\n",
    "            #TODO: Fix this jank, but just for testing now:\n",
    "            filtered_obs = policy.state_to_tensor(obs)\n",
    "            overlap_hold.append(is_overlap(filtered_obs))\n",
    "\n",
    "            op_action_real = get_opponent_action(obs, prev_obs)\n",
    "\n",
    "            if op_action_real >= 0:\n",
    "                op_action_hold.append(torch.tensor(op_action_real))\n",
    "                op_action_prob_hold.append(op_action_prob)\n",
    "                op_action_logit_hold = torch.cat((op_action_logit_hold,op_action_logit))\n",
    "                correct_hold.append(op_action_real == op_action_pred)\n",
    "\n",
    "\n",
    "            action, action_prob, _ = policy(a_obs)\n",
    "            op_action_pred, op_action_prob, op_action_logit = policy(op_obs)\n",
    "\n",
    "            prev_obs = obs\n",
    "            obs, reward, done, info = env.step(policy.convert_action(action))\n",
    "            score += reward\n",
    "\n",
    "            if done:\n",
    "                print('Episode %d (%d timesteps) - Reward: %.2f' % (episode, t, reward))\n",
    "                break\n",
    "                \n",
    "        actions_stack = torch.stack(op_action_hold)\n",
    "        actions_stack = one_hot_embedding(actions_stack, 2)\n",
    "\n",
    "        op_action_logit_hold, actions_stack = op_action_logit_hold, actions_stack\n",
    "        # Clear the previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(op_action_logit_hold, actions_stack)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Adjust weights\n",
    "        optimizer.step()\n",
    "\n",
    "        mean_overlap = np.mean(overlap_hold)\n",
    "\n",
    "\n",
    "        print(\"{}% correct guesses\".format(np.mean(correct_hold)))\n",
    "        print(\"{} Cross Entropy Loss\".format(loss.item()))\n",
    "        print(\"{} % overlap\".format(mean_overlap))\n",
    "\n",
    "        total_overlap.append(mean_overlap)\n",
    "    \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "     prev_obs, reward, done, info = env.step(2)\n",
    "obs, reward, done, info = env.step(3)\n",
    "a_obs = policy.pre_process(obs, prev_obs)\n",
    "op_obs = policy.pre_process(obs, prev_obs, opponent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d6e5bcd108>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a_obs.view(2,75,80)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d6e59ed808>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(op_obs.view(2,75,80)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3106 % overlap\n"
     ]
    }
   ],
   "source": [
    "total_overlap = []\n",
    "for episode in range(1):\n",
    "    prev_obs = None\n",
    "    obs = env.reset()\n",
    "\n",
    "    op_obs = policy.pre_process(obs, prev_obs, opponent=True)\n",
    "\n",
    "    op_action_pred, op_action_prob, op_action_logit = policy(op_obs)\n",
    "\n",
    "    '''op_action_pred = -1\n",
    "    op_action_prob = 0\n",
    "    op_action_logit = 0'''\n",
    "\n",
    "    correct_hold = []\n",
    "    op_action_hold = []\n",
    "    op_action_prob_hold = []\n",
    "    op_action_logit_hold = torch.Tensor()\n",
    "    \n",
    "    overlap_hold = []\n",
    "\n",
    "\n",
    "\n",
    "    for t in range(10000):\n",
    "        env.render()\n",
    "\n",
    "        #Preprocess the images for more model and efficient state extraction:\n",
    "        a_obs = policy.pre_process(obs, prev_obs)\n",
    "        \n",
    "        ##############################################\n",
    "        ########## Checks for Overlap ################\n",
    "        \n",
    "        #TODO: Fix this jank, but just for testing now:\n",
    "        filtered_obs = policy.state_to_tensor(obs)\n",
    "        overlap_hold.append(is_overlap(filtered_obs))\n",
    "\n",
    "\n",
    "        action, action_prob, _ = policy(a_obs)\n",
    "\n",
    "        prev_obs = obs\n",
    "        obs, reward, done, info = env.step(policy.convert_action(action))\n",
    "\n",
    "        if done:\n",
    "            print('Episode %d (%d timesteps) - Reward: %.2f' % (episode, t, reward))\n",
    "            break\n",
    "\n",
    "    \n",
    "    mean_overlap = np.mean(overlap_hold)\n",
    "    \n",
    "    print(\"{} % overlap\".format(mean_overlap))\n",
    "    \n",
    "    total_overlap.append(mean_overlap)\n",
    "    \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]),\n",
       " tensor([0.8975], grad_fn=<IndexBackward>),\n",
       " tensor([[ 1.1177, -1.0518]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy(a_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1177, -1.0518]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.layers(a_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12000])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
